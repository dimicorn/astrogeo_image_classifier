{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7987931,"sourceType":"datasetVersion","datasetId":4702184},{"sourceId":7989923,"sourceType":"datasetVersion","datasetId":4703603},{"sourceId":7994607,"sourceType":"datasetVersion","datasetId":4706799}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport warnings\n\nwarnings.filterwarnings('ignore')\ntrain_data_path = '/kaggle/input/astrogeonoisy96k/noise_96k'\nval_data_path = '/kaggle/input/astrogeo512x512/data_512x512_abs'","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:41:34.501697Z","iopub.execute_input":"2024-03-31T14:41:34.502160Z","iopub.status.idle":"2024-03-31T14:41:34.507752Z","shell.execute_reply.started":"2024-03-31T14:41:34.502111Z","shell.execute_reply":"2024-03-31T14:41:34.506776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nfrom torchvision import datasets, transforms\nimport torch.optim as optim\nfrom tqdm import tqdm\n\nclass CNN(nn.Module):\n    def __init__(self) -> None:\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n\n        self.fc1 = nn.Linear(64*16*16, 128)\n        self.fc2 = nn.Linear(128, 4)\n\n        self.relu = nn.ReLU()\n\n        self.pool = nn.MaxPool2d(2, 2)\n        self.dropout = nn.Dropout(p=0.2)\n    \n    def forward(self, image: torch.Tensor) -> torch.Tensor:\n        image = self.conv1(image)\n        image = self.relu(image)\n        image = self.pool(image)\n        image = self.conv2(image)\n        image = self.relu(image)\n        image = self.pool(image)\n        image = self.conv3(image)\n        image = self.relu(image)\n        image = self.pool(image)\n        image = image.view(-1, 64*16*16)\n        image = self.fc1(image)\n        image = self.relu(image)\n        image = self.dropout(image)\n        image = self.fc2(image)\n        return image","metadata":{"execution":{"iopub.status.busy":"2024-04-17T19:19:02.007109Z","iopub.execute_input":"2024-04-17T19:19:02.007416Z","iopub.status.idle":"2024-04-17T19:19:08.421800Z","shell.execute_reply.started":"2024-04-17T19:19:02.007391Z","shell.execute_reply":"2024-04-17T19:19:08.421016Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100\nbatch_size = 256\nlearning_rate = 1e-4\nweight_decay = 1e-5\ntrain_test_ratio = 0.8","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:41:34.530230Z","iopub.execute_input":"2024-03-31T14:41:34.530945Z","iopub.status.idle":"2024-03-31T14:41:34.542741Z","shell.execute_reply.started":"2024-03-31T14:41:34.530904Z","shell.execute_reply":"2024-03-31T14:41:34.541464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntransform = transforms.Compose([\n    transforms.Grayscale(),\n    transforms.Resize(size=(128, 128)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomAffine(degrees=(0, 0), translate=(0.1, 0.3)),\n    transforms.ToTensor()]\n)\ndata = datasets.ImageFolder(train_data_path, transform=transform)\n\ntrain_size = int(train_test_ratio * len(data))\ntest_size = len(data) - train_size\ntrain, test = torch.utils.data.random_split(data, [train_size, test_size])\ntrainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4)\ntestloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True, num_workers=4)\n\nmodel = CNN()\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\ncriterion = nn.CrossEntropyLoss()\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:41:34.546296Z","iopub.execute_input":"2024-03-31T14:41:34.546636Z","iopub.status.idle":"2024-03-31T14:41:55.680812Z","shell.execute_reply.started":"2024-03-31T14:41:34.546610Z","shell.execute_reply":"2024-03-31T14:41:55.679785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    train_loss = 0.0\n    correct, total = 0, 0\n    for data, target in tqdm(trainloader):\n        data = data.to(device)\n        target = target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        total += target.size(0)\n        _, predicted = torch.max(output.data, 1)\n        correct += (predicted == target).sum().item()\n        train_loss += loss.item() * data.size(0)\n    train_loss = train_loss / len(trainloader.dataset)\n    acc = 100 * correct / total\n    print(f'Epoch: {epoch+1} \\tTraining Loss: {train_loss:.6f} \\t Training Acc: {acc:.3f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:41:55.682612Z","iopub.execute_input":"2024-03-31T14:41:55.683023Z","iopub.status.idle":"2024-03-31T14:50:47.644316Z","shell.execute_reply.started":"2024-03-31T14:41:55.682986Z","shell.execute_reply":"2024-03-31T14:50:47.643090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test, predictions = [], []\nwith torch.no_grad():\n    correct, total = 0, 0\n    for images, labels in tqdm(testloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        y_test.extend(labels.cpu().numpy())\n        predictions.extend(predicted.cpu().numpy())\n    acc = 100 * correct / total\n    print(f'Accuracy of the network on the {total} test images:{acc:.3f} %')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:50:47.645860Z","iopub.execute_input":"2024-03-31T14:50:47.646145Z","iopub.status.idle":"2024-03-31T14:51:10.770740Z","shell.execute_reply.started":"2024-03-31T14:50:47.646119Z","shell.execute_reply":"2024-03-31T14:51:10.769644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'noise.pth')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:51:10.772311Z","iopub.execute_input":"2024-03-31T14:51:10.772642Z","iopub.status.idle":"2024-03-31T14:51:10.799884Z","shell.execute_reply.started":"2024-03-31T14:51:10.772612Z","shell.execute_reply":"2024-03-31T14:51:10.799045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(y_test, predictions)\nConfusionMatrixDisplay(cm).plot()\nplt.savefig(f'ConfMatrix_noise.png', dpi=500)\n\nprecision = precision_score(y_test, predictions, average='macro')\nrecall = recall_score(y_test, predictions, average='macro')\n    \nf1 = 2 * precision * recall / (precision + recall)\nf1_macro = f1_score(y_test, predictions, average='macro')\nf1_weighted = f1_score(y_test, predictions, average='weighted')\nprint(f'Precision: {100 * precision:.3f} %')\nprint(f'Recall: {100 * recall:.3f} %')\nprint(f'F1 Score: {100 * f1:.3f} %')\nprint(f'F1 Macro Score: {100 * f1_macro:.3f} %')\nprint(f'F1 Weighted Score: {100 * f1_weighted:.3f} %')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:51:10.802303Z","iopub.execute_input":"2024-03-31T14:51:10.802594Z","iopub.status.idle":"2024-03-31T14:51:11.837628Z","shell.execute_reply.started":"2024-03-31T14:51:10.802569Z","shell.execute_reply":"2024-03-31T14:51:11.836567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom torch.utils.data import Dataset\nfrom torchvision.io import read_image, ImageReadMode\n\nclass AstrogeoDataset(Dataset):\n    def __init__(self, dir: str, transform=None) -> None:\n        self.transform = transform\n        self.images = os.listdir(dir)\n        self.dir = dir\n\n    def __getitem__(self, index: int) -> tuple:\n        image = read_image(\n            f'{self.dir}/{self.images[index]}',\n            mode=ImageReadMode.RGB\n        )\n        file_name = self.images[index]\n        if self.transform is not None:\n            image = self.transform(image)\n        return (file_name, image)\n\n    def __len__(self) -> int:\n        return len(self.images)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:51:11.838841Z","iopub.execute_input":"2024-03-31T14:51:11.839131Z","iopub.status.idle":"2024-03-31T14:51:11.846636Z","shell.execute_reply.started":"2024-03-31T14:51:11.839105Z","shell.execute_reply":"2024-03-31T14:51:11.845631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport pandas as pd\n\ntransform = transforms.Compose([\n    transforms.ToPILImage(), transforms.Resize((128, 128)),\n    transforms.Grayscale(), transforms.ToTensor()]\n)\nval = AstrogeoDataset(val_data_path, transform=transform)\nvalloader = torch.utils.data.DataLoader(\n    val, batch_size=batch_size, shuffle=True, num_workers=4\n)\n\nmodel.eval()\nval_preds = {}\nwith torch.no_grad():\n    for file_names, images in tqdm(valloader):\n        images = images.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        val_preds.update(dict(zip(file_names, predicted.cpu().tolist())))\n        \nwith open('predicts.json', 'w') as f:\n    json.dump(val_preds, f)\n\ns1 = pd.Series(val_preds.keys())\ns2 = pd.Series(val_preds.values())\ndf = pd.concat([s1, s2], axis=1)\ndf = df.rename(columns={0: 'file_name', 1: 'predicted_class'})\ndf.to_csv('classification.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:51:11.847828Z","iopub.execute_input":"2024-03-31T14:51:11.848146Z","iopub.status.idle":"2024-03-31T14:54:21.249059Z","shell.execute_reply.started":"2024-03-31T14:51:11.848120Z","shell.execute_reply":"2024-03-31T14:54:21.248011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\nlabels = [\n    'Одиночный источник', 'Двойной источник',\n    'Источник с джетом', 'Источник с двойным джетом'\n]\nres = dict(Counter(val_preds.values()))\nres = {k: v for k, v in sorted(res.items())}\nprint(res)\nfig, ax = plt.subplots(1, 1, figsize=(10, 7))\nbar = ax.bar(res.keys(), res.values())\nax.bar_label(bar, labels=res.values())\nax.set_xlabel('Классы истинных изображений')\nax.set_ylabel('Количество')\nax.set_title('Классификация Astrogeo')\nfig.tight_layout()\nplt.savefig('histogram.png', dpi=500)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T14:54:21.250536Z","iopub.execute_input":"2024-03-31T14:54:21.250852Z","iopub.status.idle":"2024-03-31T14:54:21.580427Z","shell.execute_reply.started":"2024-03-31T14:54:21.250823Z","shell.execute_reply":"2024-03-31T14:54:21.579476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}